{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e63810eb",
   "metadata": {
    "papermill": {
     "duration": 0.028972,
     "end_time": "2022-02-21T20:38:36.455189",
     "exception": false,
     "start_time": "2022-02-21T20:38:36.426217",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Anomaly Detection\n",
    "This is an attempt to classify the scans into all the 4 classes.\n",
    "Since the data distro is kind of skewed (we have nearly $10K$ images of normal which is equal to the total number of scans of all the other classes combined), so we'll treat the *COVID*, *Viral Pneumonia* and *Lung Opacity* as an anomaly. This will be the stage one of the pipeline which will be followed by a classification of the anomalous images into the respective 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fed2dc0",
   "metadata": {
    "papermill": {
     "duration": 0.025551,
     "end_time": "2022-02-21T20:38:36.508658",
     "exception": false,
     "start_time": "2022-02-21T20:38:36.483107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38c21b8f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:36.611810Z",
     "iopub.status.busy": "2022-02-21T20:38:36.610187Z",
     "iopub.status.idle": "2022-02-21T20:38:41.905455Z",
     "shell.execute_reply": "2022-02-21T20:38:41.906289Z",
     "shell.execute_reply.started": "2022-02-21T20:32:36.173985Z"
    },
    "papermill": {
     "duration": 5.356681,
     "end_time": "2022-02-21T20:38:41.906621",
     "exception": false,
     "start_time": "2022-02-21T20:38:36.549940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, MaxPooling2D, Add\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"Imports Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c54aa52",
   "metadata": {
    "papermill": {
     "duration": 0.026176,
     "end_time": "2022-02-21T20:38:41.960490",
     "exception": false,
     "start_time": "2022-02-21T20:38:41.934314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72efe35e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:42.020473Z",
     "iopub.status.busy": "2022-02-21T20:38:42.019713Z",
     "iopub.status.idle": "2022-02-21T20:38:42.021753Z",
     "shell.execute_reply": "2022-02-21T20:38:42.022164Z",
     "shell.execute_reply.started": "2022-02-21T20:32:41.966498Z"
    },
    "papermill": {
     "duration": 0.035704,
     "end_time": "2022-02-21T20:38:42.022284",
     "exception": false,
     "start_time": "2022-02-21T20:38:41.986580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shutil.rmtree(\"/tmp/anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8fe22bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:42.079406Z",
     "iopub.status.busy": "2022-02-21T20:38:42.078594Z",
     "iopub.status.idle": "2022-02-21T20:38:42.730976Z",
     "shell.execute_reply": "2022-02-21T20:38:42.730423Z",
     "shell.execute_reply.started": "2022-02-21T20:32:41.973627Z"
    },
    "papermill": {
     "duration": 0.68248,
     "end_time": "2022-02-21T20:38:42.731111",
     "exception": false,
     "start_time": "2022-02-21T20:38:42.048631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    " !mkdir /tmp/anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae4c1f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:42.789258Z",
     "iopub.status.busy": "2022-02-21T20:38:42.788337Z",
     "iopub.status.idle": "2022-02-21T20:38:42.791795Z",
     "shell.execute_reply": "2022-02-21T20:38:42.791354Z",
     "shell.execute_reply.started": "2022-02-21T20:32:42.685189Z"
    },
    "papermill": {
     "duration": 0.034074,
     "end_time": "2022-02-21T20:38:42.791912",
     "exception": false,
     "start_time": "2022-02-21T20:38:42.757838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "\n",
    "def f2f(scr, dst='/tmp/anomaly'):\n",
    "    for jf in glob.iglob(os.path.join(scr,\"*.png\")):\n",
    "        shutil.copy(jf, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "241fec43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:42.851636Z",
     "iopub.status.busy": "2022-02-21T20:38:42.851010Z",
     "iopub.status.idle": "2022-02-21T20:38:42.854032Z",
     "shell.execute_reply": "2022-02-21T20:38:42.854416Z",
     "shell.execute_reply.started": "2022-02-21T20:32:42.696742Z"
    },
    "papermill": {
     "duration": 0.036592,
     "end_time": "2022-02-21T20:38:42.854550",
     "exception": false,
     "start_time": "2022-02-21T20:38:42.817958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nf2f(di+\"COVID\" )\\nf2f(di+\\'Lung_Opacity\\')\\nf2f(di+\"Viral Pneumonia\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "f2f(di+\"COVID\" )\n",
    "f2f(di+'Lung_Opacity')\n",
    "f2f(di+\"Viral Pneumonia\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38f01f24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:42.911682Z",
     "iopub.status.busy": "2022-02-21T20:38:42.910993Z",
     "iopub.status.idle": "2022-02-21T20:38:43.574487Z",
     "shell.execute_reply": "2022-02-21T20:38:43.573697Z",
     "shell.execute_reply.started": "2022-02-21T20:32:42.710516Z"
    },
    "papermill": {
     "duration": 0.693459,
     "end_time": "2022-02-21T20:38:43.574667",
     "exception": false,
     "start_time": "2022-02-21T20:38:42.881208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /tmp/normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8187362a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:38:43.633103Z",
     "iopub.status.busy": "2022-02-21T20:38:43.632579Z",
     "iopub.status.idle": "2022-02-21T20:39:54.566535Z",
     "shell.execute_reply": "2022-02-21T20:39:54.566045Z",
     "shell.execute_reply.started": "2022-02-21T20:32:43.424854Z"
    },
    "papermill": {
     "duration": 70.964987,
     "end_time": "2022-02-21T20:39:54.566686",
     "exception": false,
     "start_time": "2022-02-21T20:38:43.601699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "di = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/\"\n",
    "f2f(di+\"Normal\", \"/tmp/normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10f152",
   "metadata": {
    "papermill": {
     "duration": 0.026497,
     "end_time": "2022-02-21T20:39:54.620571",
     "exception": false,
     "start_time": "2022-02-21T20:39:54.594074",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we'll create a `dataset` of all the normal samples to train the *anomaly detection system*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a827a0b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:54.680844Z",
     "iopub.status.busy": "2022-02-21T20:39:54.680032Z",
     "iopub.status.idle": "2022-02-21T20:39:57.848024Z",
     "shell.execute_reply": "2022-02-21T20:39:57.848622Z",
     "shell.execute_reply.started": "2022-02-21T20:33:30.732199Z"
    },
    "papermill": {
     "duration": 3.201763,
     "end_time": "2022-02-21T20:39:57.848815",
     "exception": false,
     "start_time": "2022-02-21T20:39:54.647052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10192 files belonging to 1 classes.\n",
      "Using 9173 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 20:39:54.995668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:55.106688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:55.107376: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:55.110080: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-21 20:39:55.111068: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:55.111800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:55.112436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:57.220206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:57.221139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:57.221844: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-21 20:39:57.222467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10192 files belonging to 1 classes.\n",
      "Using 1019 files for validation.\n"
     ]
    }
   ],
   "source": [
    "encotds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/normal\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"training\", interpolation = \"bicubic\")\n",
    "\n",
    "encovds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/normal\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"validation\", interpolation = \"bicubic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dee041c",
   "metadata": {
    "papermill": {
     "duration": 0.02726,
     "end_time": "2022-02-21T20:39:57.904344",
     "exception": false,
     "start_time": "2022-02-21T20:39:57.877084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, the dataset of all the anomalous samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8772e91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:57.964224Z",
     "iopub.status.busy": "2022-02-21T20:39:57.963444Z",
     "iopub.status.idle": "2022-02-21T20:39:57.969570Z",
     "shell.execute_reply": "2022-02-21T20:39:57.969115Z",
     "shell.execute_reply.started": "2022-02-21T20:33:33.904355Z"
    },
    "papermill": {
     "duration": 0.03712,
     "end_time": "2022-02-21T20:39:57.969679",
     "exception": false,
     "start_time": "2022-02-21T20:39:57.932559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanoTds = tf.keras.preprocessing.image_dataset_from_directory(\\n    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \\n    image_size = (224, 224), shuffle = True, seed = 42, \\n    validation_split = 0.1, subset = \"training\", interpolation = \"bicubic\")\\n\\nanoVds = tf.keras.preprocessing.image_dataset_from_directory(\\n    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \\n    image_size = (224, 224), shuffle = True, seed = 42, \\n    validation_split = 0.1, subset = \"validation\", interpolation = \"bicubic\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "anoTds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"training\", interpolation = \"bicubic\")\n",
    "\n",
    "anoVds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"validation\", interpolation = \"bicubic\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe53eb7",
   "metadata": {
    "papermill": {
     "duration": 0.028252,
     "end_time": "2022-02-21T20:39:58.027209",
     "exception": false,
     "start_time": "2022-02-21T20:39:57.998957",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbab4fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.092343Z",
     "iopub.status.busy": "2022-02-21T20:39:58.090805Z",
     "iopub.status.idle": "2022-02-21T20:39:58.093282Z",
     "shell.execute_reply": "2022-02-21T20:39:58.093721Z",
     "shell.execute_reply.started": "2022-02-21T20:33:33.915876Z"
    },
    "papermill": {
     "duration": 0.038396,
     "end_time": "2022-02-21T20:39:58.093842",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.055446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True):\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2D(filters=f1, kernel_size=1, padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2D(filters=f2, kernel_size=f, padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2D(filters=f3, kernel_size=1, padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    \n",
    "    X = tf.keras.layers.Add()([X_skip, X])\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7707d241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.158256Z",
     "iopub.status.busy": "2022-02-21T20:39:58.157572Z",
     "iopub.status.idle": "2022-02-21T20:39:58.160111Z",
     "shell.execute_reply": "2022-02-21T20:39:58.159717Z",
     "shell.execute_reply.started": "2022-02-21T20:33:33.926875Z"
    },
    "papermill": {
     "duration": 0.038247,
     "end_time": "2022-02-21T20:39:58.160214",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.121967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(X, f, filters, s=2, training=True):\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2D(filters = f1, kernel_size = 1, strides = (s, s), padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2D(filters = f2, kernel_size = f, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X) \n",
    "    \n",
    "    X = Conv2D(filters = f3, kernel_size = 1, strides = (1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization()(X, training = training)\n",
    "    \n",
    "    X_skip = Conv2D(filters = f3, kernel_size = 1, strides=(s,s), padding='valid')(X_skip)\n",
    "    X_skip = BatchNormalization()(X_skip, training = training)\n",
    "    \n",
    "    X = Add()([X, X_skip])\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3117cb91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.223616Z",
     "iopub.status.busy": "2022-02-21T20:39:58.223079Z",
     "iopub.status.idle": "2022-02-21T20:39:58.226527Z",
     "shell.execute_reply": "2022-02-21T20:39:58.226127Z",
     "shell.execute_reply.started": "2022-02-21T20:33:33.941109Z"
    },
    "papermill": {
     "duration": 0.038608,
     "end_time": "2022-02-21T20:39:58.226641",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.188033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Trans_conv_block(X, f, filters, s=2, training=True):\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2DTranspose(filters = f1, kernel_size = 1, strides = (s, s), padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2DTranspose(filters = f2, kernel_size = f, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X) \n",
    "    \n",
    "    X = Conv2DTranspose(filters = f3, kernel_size = 1, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization()(X, training = training)\n",
    "    \n",
    "    X_skip = Conv2DTranspose(filters = f3, kernel_size = 1, strides=(s,s), padding='valid')(X_skip)\n",
    "    X_skip = BatchNormalization()(X_skip, training = training)\n",
    "    \n",
    "    X = Add()([X, X_skip])\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "957f15df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.291701Z",
     "iopub.status.busy": "2022-02-21T20:39:58.291109Z",
     "iopub.status.idle": "2022-02-21T20:39:58.293356Z",
     "shell.execute_reply": "2022-02-21T20:39:58.293764Z",
     "shell.execute_reply.started": "2022-02-21T20:33:33.953605Z"
    },
    "papermill": {
     "duration": 0.037498,
     "end_time": "2022-02-21T20:39:58.293896",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.256398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def enco(input_shape=(224,224,3)):\n",
    "    \n",
    "    X_inp = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    X = Conv2D(64, (3,3), strides = (2,2))(X_inp)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    X = conv_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    X = conv_block(X, 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=X_inp,outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bacd9d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.353607Z",
     "iopub.status.busy": "2022-02-21T20:39:58.353064Z",
     "iopub.status.idle": "2022-02-21T20:39:58.765764Z",
     "shell.execute_reply": "2022-02-21T20:39:58.765310Z",
     "shell.execute_reply.started": "2022-02-21T20:33:33.966764Z"
    },
    "papermill": {
     "duration": 0.444148,
     "end_time": "2022-02-21T20:39:58.765891",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.321743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 512)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, 111, 111, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 55, 55, 64)   36928       tf.nn.relu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_2 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 55, 55, 256)  16640       tf.nn.relu_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 55, 55, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_3 (TFOpLambda)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 55, 55, 64)   16448       tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_4 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 55, 55, 64)   36928       tf.nn.relu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_5 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 55, 55, 256)  16640       tf.nn.relu_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           tf.nn.relu_3[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_6 (TFOpLambda)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 55, 55, 64)   16448       tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_7 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 55, 55, 64)   36928       tf.nn.relu_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_8 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 55, 55, 256)  16640       tf.nn.relu_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           tf.nn.relu_6[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  32896       tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_10 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      tf.nn.relu_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_11 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 512)  66048       tf.nn.relu_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  131584      tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_12 (TFOpLambda)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       tf.nn.relu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_13 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      tf.nn.relu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_14 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       tf.nn.relu_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           tf.nn.relu_12[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_15 (TFOpLambda)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_16 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      tf.nn.relu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_17 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       tf.nn.relu_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           tf.nn.relu_15[0][0]              \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_18 (TFOpLambda)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,170,048\n",
      "Trainable params: 1,161,472\n",
      "Non-trainable params: 8,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = enco()\n",
    "print(mod.output.shape)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654f7eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.834484Z",
     "iopub.status.busy": "2022-02-21T20:39:58.832922Z",
     "iopub.status.idle": "2022-02-21T20:39:58.835122Z",
     "shell.execute_reply": "2022-02-21T20:39:58.835537Z",
     "shell.execute_reply.started": "2022-02-21T20:33:34.377231Z"
    },
    "papermill": {
     "duration": 0.040892,
     "end_time": "2022-02-21T20:39:58.835663",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.794771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deco(input_shape=(28,28,512)):\n",
    "    \n",
    "    X_inp = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    X = Trans_conv_block(X_inp, 3, [256, 256, 128], s=2, training=True)\n",
    "    X = identity_block(X, 3, [256, 128, 128])\n",
    "    X = identity_block(X, 3, [256, 128, 128])\n",
    "    \n",
    "    X = Trans_conv_block(X, 3, [128, 64, 64], s=1, training=True)\n",
    "    X = identity_block(X, 3, [128, 64, 64])\n",
    "    X = identity_block(X, 3, [128, 64, 64])\n",
    "    \n",
    "    #X = Conv2DTranspose(64, (7,7), strides = (2,2), padding='valid')(X)\n",
    "    X = Trans_conv_block(X, 3, [64, 32, 32], s=2, training=True)\n",
    "    X = identity_block(X, 3, [64, 32, 32])\n",
    "    X = identity_block(X, 3, [64, 32, 32])\n",
    "    \n",
    "    X = Trans_conv_block(X, 11, [64, 32, 32], s=2, training=True)\n",
    "    X = Conv2D(filters=3 , kernel_size = 1, strides = 1, padding='valid')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=X_inp,outputs=X)\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b9a7166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:58.900402Z",
     "iopub.status.busy": "2022-02-21T20:39:58.899631Z",
     "iopub.status.idle": "2022-02-21T20:39:59.551557Z",
     "shell.execute_reply": "2022-02-21T20:39:59.551994Z",
     "shell.execute_reply.started": "2022-02-21T20:33:34.388511Z"
    },
    "papermill": {
     "duration": 0.687945,
     "end_time": "2022-02-21T20:39:59.552151",
     "exception": false,
     "start_time": "2022-02-21T20:39:58.864206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 224, 224, 3)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 512) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 56, 56, 256)  131328      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 56, 56, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_19 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 56, 56, 256)  590080      tf.nn.relu_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 56, 56, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_20 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 128)  32896       tf.nn.relu_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 56, 56, 128)  65664       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 56, 56, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 56, 56, 128)  512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 56, 56, 128)  0           batch_normalization_23[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_21 (TFOpLambda)      (None, 56, 56, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 56, 56, 256)  33024       tf.nn.relu_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 56, 56, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_22 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 56, 56, 128)  295040      tf.nn.relu_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 56, 56, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_23 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 56, 56, 128)  16512       tf.nn.relu_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 56, 56, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 56, 56, 128)  0           tf.nn.relu_21[0][0]              \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_24 (TFOpLambda)      (None, 56, 56, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 56, 56, 256)  33024       tf.nn.relu_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 56, 56, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_25 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 56, 56, 128)  295040      tf.nn.relu_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 56, 56, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_26 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 56, 56, 128)  16512       tf.nn.relu_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 56, 56, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 56, 56, 128)  0           tf.nn.relu_24[0][0]              \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_27 (TFOpLambda)      (None, 56, 56, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 56, 56, 128)  16512       tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 56, 56, 128)  512         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_28 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 56, 56, 64)   73792       tf.nn.relu_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 56, 56, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_29 (TFOpLambda)      (None, 56, 56, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 56, 56, 64)   4160        tf.nn.relu_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 56, 56, 64)   8256        tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 56, 56, 64)   256         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 56, 56, 64)   256         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 56, 56, 64)   0           batch_normalization_33[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_30 (TFOpLambda)      (None, 56, 56, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 56, 56, 128)  8320        tf.nn.relu_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 56, 56, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_31 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 56, 56, 64)   73792       tf.nn.relu_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 56, 56, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_32 (TFOpLambda)      (None, 56, 56, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 56, 56, 64)   4160        tf.nn.relu_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 56, 56, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 56, 56, 64)   0           tf.nn.relu_30[0][0]              \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_33 (TFOpLambda)      (None, 56, 56, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 56, 56, 128)  8320        tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 56, 56, 128)  512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_34 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 56, 56, 64)   73792       tf.nn.relu_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 56, 56, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_35 (TFOpLambda)      (None, 56, 56, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 56, 56, 64)   4160        tf.nn.relu_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 56, 56, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 56, 56, 64)   0           tf.nn.relu_33[0][0]              \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_36 (TFOpLambda)      (None, 56, 56, 64)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 112, 112, 64) 4160        tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 112, 112, 64) 256         conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_37 (TFOpLambda)      (None, 112, 112, 64) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 112, 112, 32) 18464       tf.nn.relu_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 112, 112, 32) 128         conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_38 (TFOpLambda)      (None, 112, 112, 32) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 112, 112, 32) 1056        tf.nn.relu_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 112, 112, 32) 2080        tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 112, 112, 32) 128         conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 112, 112, 32) 128         conv2d_transpose_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 112, 112, 32) 0           batch_normalization_43[0][0]     \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_39 (TFOpLambda)      (None, 112, 112, 32) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 112, 112, 64) 2112        tf.nn.relu_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 112, 112, 64) 256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_40 (TFOpLambda)      (None, 112, 112, 64) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 112, 112, 32) 18464       tf.nn.relu_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 112, 112, 32) 128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_41 (TFOpLambda)      (None, 112, 112, 32) 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 112, 112, 32) 1056        tf.nn.relu_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 112, 112, 32) 128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 112, 112, 32) 0           tf.nn.relu_39[0][0]              \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_42 (TFOpLambda)      (None, 112, 112, 32) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 112, 112, 64) 2112        tf.nn.relu_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 112, 112, 64) 256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_43 (TFOpLambda)      (None, 112, 112, 64) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 112, 112, 32) 18464       tf.nn.relu_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 112, 112, 32) 128         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_44 (TFOpLambda)      (None, 112, 112, 32) 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 112, 112, 32) 1056        tf.nn.relu_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 112, 112, 32) 128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 112, 112, 32) 0           tf.nn.relu_42[0][0]              \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_45 (TFOpLambda)      (None, 112, 112, 32) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 224, 224, 64) 2112        tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 224, 224, 64) 256         conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_46 (TFOpLambda)      (None, 224, 224, 64) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 224, 224, 32) 247840      tf.nn.relu_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_47 (TFOpLambda)      (None, 224, 224, 32) 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 224, 224, 32) 1056        tf.nn.relu_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 224, 224, 32) 1056        tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 224, 224, 32) 0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_48 (TFOpLambda)      (None, 224, 224, 32) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 224, 224, 3)  99          tf.nn.relu_48[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,118,371\n",
      "Trainable params: 2,111,971\n",
      "Non-trainable params: 6,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = deco()\n",
    "print(mod.output.shape)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a50ef922",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:59.617925Z",
     "iopub.status.busy": "2022-02-21T20:39:59.617146Z",
     "iopub.status.idle": "2022-02-21T20:39:59.620665Z",
     "shell.execute_reply": "2022-02-21T20:39:59.620183Z",
     "shell.execute_reply.started": "2022-02-21T20:33:35.063866Z"
    },
    "papermill": {
     "duration": 0.038271,
     "end_time": "2022-02-21T20:39:59.620821",
     "exception": false,
     "start_time": "2022-02-21T20:39:59.582550",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = enco(input_shape=(224,224,3))\n",
    "        self.decoder = deco(input_shape=(28,28,512)) \n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e51ae25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:39:59.684383Z",
     "iopub.status.busy": "2022-02-21T20:39:59.683556Z",
     "iopub.status.idle": "2022-02-21T20:40:00.624498Z",
     "shell.execute_reply": "2022-02-21T20:40:00.624001Z",
     "shell.execute_reply.started": "2022-02-21T20:33:35.077683Z"
    },
    "papermill": {
     "duration": 0.97453,
     "end_time": "2022-02-21T20:40:00.624658",
     "exception": false,
     "start_time": "2022-02-21T20:39:59.650128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss = 'MeanSquaredError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eef64fa6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:40:00.688339Z",
     "iopub.status.busy": "2022-02-21T20:40:00.687838Z",
     "iopub.status.idle": "2022-02-21T20:40:00.719095Z",
     "shell.execute_reply": "2022-02-21T20:40:00.718230Z",
     "shell.execute_reply.started": "2022-02-21T20:33:36.120914Z"
    },
    "papermill": {
     "duration": 0.065058,
     "end_time": "2022-02-21T20:40:00.719204",
     "exception": false,
     "start_time": "2022-02-21T20:40:00.654146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tds = encotds.map(lambda x : (x,x))\n",
    "vds = encovds.map(lambda x : (x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3757b2df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-21T20:40:00.783665Z",
     "iopub.status.busy": "2022-02-21T20:40:00.783128Z",
     "iopub.status.idle": "2022-02-22T02:14:09.445795Z",
     "shell.execute_reply": "2022-02-22T02:14:09.427466Z",
     "shell.execute_reply.started": "2022-02-21T20:33:36.160936Z"
    },
    "papermill": {
     "duration": 20048.697528,
     "end_time": "2022-02-22T02:14:09.445976",
     "exception": false,
     "start_time": "2022-02-21T20:40:00.748448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 20:40:00.818009: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-21 20:40:07.293293: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 147s 453ms/step - loss: 18690.2012 - val_loss: 16640.1094\n",
      "Epoch 2/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 13086.0078 - val_loss: 9664.3398\n",
      "Epoch 3/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 6164.9468 - val_loss: 3158.6021\n",
      "Epoch 4/150\n",
      "287/287 [==============================] - 125s 433ms/step - loss: 1502.6449 - val_loss: 558.3231\n",
      "Epoch 5/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 222.6151 - val_loss: 94.1266\n",
      "Epoch 6/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 60.4764 - val_loss: 51.2330\n",
      "Epoch 7/150\n",
      "287/287 [==============================] - 126s 434ms/step - loss: 46.1944 - val_loss: 40.5191\n",
      "Epoch 8/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 41.0890 - val_loss: 36.7987\n",
      "Epoch 9/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 37.2878 - val_loss: 34.5311\n",
      "Epoch 10/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 36.8675 - val_loss: 37.2967\n",
      "Epoch 11/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 35.0674 - val_loss: 30.2220\n",
      "Epoch 12/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 37.6544 - val_loss: 39.3228\n",
      "Epoch 13/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 35.3987 - val_loss: 32.0758\n",
      "Epoch 14/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 30.8513 - val_loss: 33.1504\n",
      "Epoch 15/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 31.1612 - val_loss: 30.7767\n",
      "Epoch 16/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 30.3061 - val_loss: 36.6979\n",
      "Epoch 17/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 28.5899 - val_loss: 25.5695\n",
      "Epoch 18/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 26.0824 - val_loss: 27.7750\n",
      "Epoch 19/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 24.9283 - val_loss: 36.6178\n",
      "Epoch 20/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 26.0561 - val_loss: 31.8739\n",
      "Epoch 21/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 23.9826 - val_loss: 23.7033\n",
      "Epoch 22/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 22.6899 - val_loss: 27.1984\n",
      "Epoch 23/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 21.2871 - val_loss: 19.7951\n",
      "Epoch 24/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 19.9911 - val_loss: 22.1412\n",
      "Epoch 25/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 20.2678 - val_loss: 23.9988\n",
      "Epoch 26/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 20.0241 - val_loss: 31.1817\n",
      "Epoch 27/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 21.0359 - val_loss: 26.0475\n",
      "Epoch 28/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 18.1527 - val_loss: 21.6211\n",
      "Epoch 29/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 16.6603 - val_loss: 18.8116\n",
      "Epoch 30/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 16.1394 - val_loss: 20.7365\n",
      "Epoch 31/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 16.5793 - val_loss: 19.4559\n",
      "Epoch 32/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 17.0071 - val_loss: 26.4299\n",
      "Epoch 33/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 17.5987 - val_loss: 18.5705\n",
      "Epoch 34/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 16.8646 - val_loss: 19.7295\n",
      "Epoch 35/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 15.6298 - val_loss: 17.4415\n",
      "Epoch 36/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 15.0752 - val_loss: 17.5773\n",
      "Epoch 37/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 15.7510 - val_loss: 23.4125\n",
      "Epoch 38/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 15.9787 - val_loss: 15.2798\n",
      "Epoch 39/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 17.1321 - val_loss: 20.3903\n",
      "Epoch 40/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 15.7956 - val_loss: 16.4548\n",
      "Epoch 41/150\n",
      "287/287 [==============================] - 125s 436ms/step - loss: 15.3271 - val_loss: 16.5658\n",
      "Epoch 42/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 14.0335 - val_loss: 17.9683\n",
      "Epoch 43/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 13.4521 - val_loss: 15.0264\n",
      "Epoch 44/150\n",
      "287/287 [==============================] - 130s 450ms/step - loss: 13.7464 - val_loss: 18.1166\n",
      "Epoch 45/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 13.4100 - val_loss: 16.1777\n",
      "Epoch 46/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.9869 - val_loss: 15.0835\n",
      "Epoch 47/150\n",
      "287/287 [==============================] - 130s 449ms/step - loss: 12.5222 - val_loss: 16.1138\n",
      "Epoch 48/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.6121 - val_loss: 12.9560\n",
      "Epoch 49/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.3567 - val_loss: 21.4623\n",
      "Epoch 50/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 14.9963 - val_loss: 15.2867\n",
      "Epoch 51/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 12.0129 - val_loss: 13.8406\n",
      "Epoch 52/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.5485 - val_loss: 15.6726\n",
      "Epoch 53/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 14.1150 - val_loss: 18.4453\n",
      "Epoch 54/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 14.1973 - val_loss: 20.0234\n",
      "Epoch 55/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 13.0036 - val_loss: 13.5532\n",
      "Epoch 56/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.4399 - val_loss: 15.1018\n",
      "Epoch 57/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.8872 - val_loss: 29.0240\n",
      "Epoch 58/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.2576 - val_loss: 14.0022\n",
      "Epoch 59/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.2136 - val_loss: 16.1221\n",
      "Epoch 60/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.3587 - val_loss: 11.6016\n",
      "Epoch 61/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.0162 - val_loss: 15.9220\n",
      "Epoch 62/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.0933 - val_loss: 13.2025\n",
      "Epoch 63/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 11.4101 - val_loss: 14.3406\n",
      "Epoch 64/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 11.9270 - val_loss: 14.9257\n",
      "Epoch 65/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 10.6035 - val_loss: 14.3155\n",
      "Epoch 66/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.2059 - val_loss: 15.3804\n",
      "Epoch 67/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.6155 - val_loss: 12.8791\n",
      "Epoch 68/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 10.9360 - val_loss: 13.9340\n",
      "Epoch 69/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 10.3433 - val_loss: 17.6097\n",
      "Epoch 70/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 9.9773 - val_loss: 13.0975\n",
      "Epoch 71/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 10.9928 - val_loss: 15.4633\n",
      "Epoch 72/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 10.3584 - val_loss: 13.5129\n",
      "Epoch 73/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 9.9307 - val_loss: 13.7143\n",
      "Epoch 74/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 10.0491 - val_loss: 12.4214\n",
      "Epoch 75/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 9.6351 - val_loss: 14.3832\n",
      "Epoch 76/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 12.5566 - val_loss: 13.5597\n",
      "Epoch 77/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 9.9526 - val_loss: 11.9881\n",
      "Epoch 78/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 10.1638 - val_loss: 13.1260\n",
      "Epoch 79/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.5389 - val_loss: 11.7635\n",
      "Epoch 80/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 9.7711 - val_loss: 14.1078\n",
      "Epoch 81/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 9.5864 - val_loss: 11.9973\n",
      "Epoch 82/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 9.5547 - val_loss: 12.7689\n",
      "Epoch 83/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.5567 - val_loss: 11.2230\n",
      "Epoch 84/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 9.9823 - val_loss: 14.5373\n",
      "Epoch 85/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.2903 - val_loss: 10.5138\n",
      "Epoch 86/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.8038 - val_loss: 14.2867\n",
      "Epoch 87/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.4151 - val_loss: 13.9995\n",
      "Epoch 88/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.1661 - val_loss: 13.1326\n",
      "Epoch 89/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.7360 - val_loss: 13.4421\n",
      "Epoch 90/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 8.7753 - val_loss: 11.2192\n",
      "Epoch 91/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.7595 - val_loss: 13.9142\n",
      "Epoch 92/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.5730 - val_loss: 15.9191\n",
      "Epoch 93/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.8381 - val_loss: 11.5562\n",
      "Epoch 94/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.3315 - val_loss: 15.4102\n",
      "Epoch 95/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.5843 - val_loss: 13.5812\n",
      "Epoch 96/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.7680 - val_loss: 11.3888\n",
      "Epoch 97/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 8.5857 - val_loss: 14.1147\n",
      "Epoch 98/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 9.1775 - val_loss: 11.9829\n",
      "Epoch 99/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 8.6341 - val_loss: 11.4960\n",
      "Epoch 100/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.0831 - val_loss: 13.2375\n",
      "Epoch 101/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 8.6413 - val_loss: 10.8726\n",
      "Epoch 102/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.8835 - val_loss: 18.0846\n",
      "Epoch 103/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.9636 - val_loss: 12.0908\n",
      "Epoch 104/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 9.1188 - val_loss: 17.2151\n",
      "Epoch 105/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.1988 - val_loss: 11.8703\n",
      "Epoch 106/150\n",
      "287/287 [==============================] - 127s 439ms/step - loss: 7.4292 - val_loss: 16.8745\n",
      "Epoch 107/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.6562 - val_loss: 11.4399\n",
      "Epoch 108/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.9450 - val_loss: 10.6631\n",
      "Epoch 109/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.2221 - val_loss: 17.7098\n",
      "Epoch 110/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 8.0377 - val_loss: 11.3877\n",
      "Epoch 111/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 7.8297 - val_loss: 11.2483\n",
      "Epoch 112/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.2640 - val_loss: 11.1808\n",
      "Epoch 113/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.7106 - val_loss: 13.0001\n",
      "Epoch 114/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.5239 - val_loss: 12.8302\n",
      "Epoch 115/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.9740 - val_loss: 10.5007\n",
      "Epoch 116/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.3102 - val_loss: 10.7279\n",
      "Epoch 117/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.9526 - val_loss: 11.5645\n",
      "Epoch 118/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.6957 - val_loss: 11.5911\n",
      "Epoch 119/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.5196 - val_loss: 8.8829\n",
      "Epoch 120/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.4392 - val_loss: 10.5808\n",
      "Epoch 121/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.8101 - val_loss: 11.3261\n",
      "Epoch 122/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.8093 - val_loss: 11.8234\n",
      "Epoch 123/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 7.7976 - val_loss: 10.1651\n",
      "Epoch 124/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.4276 - val_loss: 13.4207\n",
      "Epoch 125/150\n",
      "287/287 [==============================] - 129s 449ms/step - loss: 7.7861 - val_loss: 11.0225\n",
      "Epoch 126/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 7.6433 - val_loss: 12.7078\n",
      "Epoch 127/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 7.3537 - val_loss: 10.6837\n",
      "Epoch 128/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.1393 - val_loss: 10.2399\n",
      "Epoch 129/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.0457 - val_loss: 14.8335\n",
      "Epoch 130/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.0311 - val_loss: 10.4637\n",
      "Epoch 131/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.8914 - val_loss: 10.5353\n",
      "Epoch 132/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.8983 - val_loss: 11.9420\n",
      "Epoch 133/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.1373 - val_loss: 10.4732\n",
      "Epoch 134/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.2337 - val_loss: 9.9608\n",
      "Epoch 135/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 6.7701 - val_loss: 10.7988\n",
      "Epoch 136/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.3108 - val_loss: 11.9460\n",
      "Epoch 137/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.1866 - val_loss: 11.3815\n",
      "Epoch 138/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 6.7203 - val_loss: 10.4678\n",
      "Epoch 139/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 7.3195 - val_loss: 10.6813\n",
      "Epoch 140/150\n",
      "287/287 [==============================] - 130s 450ms/step - loss: 6.7889 - val_loss: 10.6572\n",
      "Epoch 141/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.1238 - val_loss: 10.7630\n",
      "Epoch 142/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.5220 - val_loss: 10.9987\n",
      "Epoch 143/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.5006 - val_loss: 11.4038\n",
      "Epoch 144/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 6.7628 - val_loss: 9.9053\n",
      "Epoch 145/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.7703 - val_loss: 12.0514\n",
      "Epoch 146/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 6.8231 - val_loss: 10.8217\n",
      "Epoch 147/150\n",
      "287/287 [==============================] - 127s 439ms/step - loss: 7.5159 - val_loss: 11.5916\n",
      "Epoch 148/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 7.2381 - val_loss: 11.4285\n",
      "Epoch 149/150\n",
      "287/287 [==============================] - 126s 438ms/step - loss: 6.6439 - val_loss: 10.4897\n",
      "Epoch 150/150\n",
      "287/287 [==============================] - 126s 439ms/step - loss: 7.1718 - val_loss: 10.2980\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(tds,\n",
    "                epochs=150,\n",
    "                shuffle=True,\n",
    "                validation_data=vds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "452a1e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T02:14:37.864008Z",
     "iopub.status.busy": "2022-02-22T02:14:37.863257Z",
     "iopub.status.idle": "2022-02-22T02:15:08.087670Z",
     "shell.execute_reply": "2022-02-22T02:15:08.086998Z",
     "shell.execute_reply.started": "2022-02-21T20:37:03.382611Z"
    },
    "papermill": {
     "duration": 44.051191,
     "end_time": "2022-02-22T02:15:08.087846",
     "exception": false,
     "start_time": "2022-02-22T02:14:24.036655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 02:14:50.645952: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "autoencoder.save(\"/savedModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1ca82fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T02:15:36.882585Z",
     "iopub.status.busy": "2022-02-22T02:15:36.881799Z",
     "iopub.status.idle": "2022-02-22T02:15:48.628797Z",
     "shell.execute_reply": "2022-02-22T02:15:48.628083Z",
     "shell.execute_reply.started": "2022-02-21T20:37:33.722782Z"
    },
    "papermill": {
     "duration": 26.369577,
     "end_time": "2022-02-22T02:15:48.628972",
     "exception": false,
     "start_time": "2022-02-22T02:15:22.259395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('/savedModel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b13b39d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T02:16:17.120380Z",
     "iopub.status.busy": "2022-02-22T02:16:17.118844Z",
     "iopub.status.idle": "2022-02-22T02:16:17.120984Z",
     "shell.execute_reply": "2022-02-22T02:16:17.121379Z",
     "shell.execute_reply.started": "2022-02-21T20:37:45.526982Z"
    },
    "papermill": {
     "duration": 13.93868,
     "end_time": "2022-02-22T02:16:17.121541",
     "exception": false,
     "start_time": "2022-02-22T02:16:03.182861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = history.history.keys()\n",
    "metrics = list(l)\n",
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "383b3122",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T02:16:45.923664Z",
     "iopub.status.busy": "2022-02-22T02:16:45.922996Z",
     "iopub.status.idle": "2022-02-22T02:16:46.204746Z",
     "shell.execute_reply": "2022-02-22T02:16:46.205189Z",
     "shell.execute_reply.started": "2022-02-21T20:37:45.538478Z"
    },
    "papermill": {
     "duration": 14.251578,
     "end_time": "2022-02-22T02:16:46.205342",
     "exception": false,
     "start_time": "2022-02-22T02:16:31.953764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(l)//2):\n",
    "    tr = metrics[i]\n",
    "    val = \"val_\" + tr\n",
    "    df_pl= df[[tr,val]]\n",
    "    df_pl.rename(columns={tr:'Train',val:'Validation'},inplace=True)\n",
    "    df_pl.plot(title='Model '+tr,figsize=(12,8)).set(xlabel='Epoch',ylabel=tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b0a7b",
   "metadata": {
    "papermill": {
     "duration": 14.343054,
     "end_time": "2022-02-22T02:17:14.492517",
     "exception": false,
     "start_time": "2022-02-22T02:17:00.149463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's try the model on a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "763401a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T02:17:43.272937Z",
     "iopub.status.busy": "2022-02-22T02:17:43.272241Z",
     "iopub.status.idle": "2022-02-22T02:17:44.830476Z",
     "shell.execute_reply": "2022-02-22T02:17:44.829980Z",
     "shell.execute_reply.started": "2022-02-21T20:37:45.832114Z"
    },
    "papermill": {
     "duration": 15.965193,
     "end_time": "2022-02-22T02:17:44.830639",
     "exception": false,
     "start_time": "2022-02-22T02:17:28.865446",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img = cv2.imread(\"/tmp/normal/Normal-1.png\", 1)\n",
    "img = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "img_list = []\n",
    "img_list.append(np.array(img))\n",
    "x = np.asarray(img_list)\n",
    "recon = autoencoder.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c95607cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T02:18:13.602437Z",
     "iopub.status.busy": "2022-02-22T02:18:13.601593Z",
     "iopub.status.idle": "2022-02-22T02:18:13.606291Z",
     "shell.execute_reply": "2022-02-22T02:18:13.606745Z",
     "shell.execute_reply.started": "2022-02-21T20:37:47.656127Z"
    },
    "papermill": {
     "duration": 14.717464,
     "end_time": "2022-02-22T02:18:13.606892",
     "exception": false,
     "start_time": "2022-02-22T02:17:58.889428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.220528"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = recon - x\n",
    "np.average(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646dd868",
   "metadata": {
    "papermill": {
     "duration": 14.386489,
     "end_time": "2022-02-22T02:18:42.133160",
     "exception": false,
     "start_time": "2022-02-22T02:18:27.746671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20431.582342,
   "end_time": "2022-02-22T02:18:59.760411",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-21T20:38:28.178069",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
