{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f8b9357",
   "metadata": {
    "papermill": {
     "duration": 0.051937,
     "end_time": "2022-02-22T19:09:36.647316",
     "exception": false,
     "start_time": "2022-02-22T19:09:36.595379",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Anomaly Detection\n",
    "This is an attempt to classify the scans into all the 4 classes.\n",
    "Since the data distro is kind of skewed (we have nearly $10K$ images of normal which is equal to the total number of scans of all the other classes combined), so we'll treat the *COVID*, *Viral Pneumonia* and *Lung Opacity* as an anomaly. This will be the stage one of the pipeline which will be followed by a classification of the anomalous images into the respective 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc30fa",
   "metadata": {
    "papermill": {
     "duration": 0.037617,
     "end_time": "2022-02-22T19:09:36.719649",
     "exception": false,
     "start_time": "2022-02-22T19:09:36.682032",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8ec4a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:36.782970Z",
     "iopub.status.busy": "2022-02-22T19:09:36.782175Z",
     "iopub.status.idle": "2022-02-22T19:09:42.107739Z",
     "shell.execute_reply": "2022-02-22T19:09:42.107164Z",
     "shell.execute_reply.started": "2022-02-22T19:03:05.970485Z"
    },
    "papermill": {
     "duration": 5.362412,
     "end_time": "2022-02-22T19:09:42.107880",
     "exception": false,
     "start_time": "2022-02-22T19:09:36.745468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Complete\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import h5py\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, MaxPooling2D, Add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"Imports Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3b9a2b",
   "metadata": {
    "papermill": {
     "duration": 0.025934,
     "end_time": "2022-02-22T19:09:42.160478",
     "exception": false,
     "start_time": "2022-02-22T19:09:42.134544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823d7926",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:42.220627Z",
     "iopub.status.busy": "2022-02-22T19:09:42.219815Z",
     "iopub.status.idle": "2022-02-22T19:09:42.222118Z",
     "shell.execute_reply": "2022-02-22T19:09:42.221702Z",
     "shell.execute_reply.started": "2022-02-22T19:03:05.979583Z"
    },
    "papermill": {
     "duration": 0.035484,
     "end_time": "2022-02-22T19:09:42.222228",
     "exception": false,
     "start_time": "2022-02-22T19:09:42.186744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shutil.rmtree(\"/tmp/anomaly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "205357fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:42.278078Z",
     "iopub.status.busy": "2022-02-22T19:09:42.277371Z",
     "iopub.status.idle": "2022-02-22T19:09:42.936936Z",
     "shell.execute_reply": "2022-02-22T19:09:42.936459Z",
     "shell.execute_reply.started": "2022-02-22T19:03:05.989691Z"
    },
    "papermill": {
     "duration": 0.688962,
     "end_time": "2022-02-22T19:09:42.937065",
     "exception": false,
     "start_time": "2022-02-22T19:09:42.248103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /tmp/anomaly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0529a68f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:42.996046Z",
     "iopub.status.busy": "2022-02-22T19:09:42.995228Z",
     "iopub.status.idle": "2022-02-22T19:09:42.997171Z",
     "shell.execute_reply": "2022-02-22T19:09:42.997558Z",
     "shell.execute_reply.started": "2022-02-22T19:03:06.795184Z"
    },
    "papermill": {
     "duration": 0.033529,
     "end_time": "2022-02-22T19:09:42.997685",
     "exception": false,
     "start_time": "2022-02-22T19:09:42.964156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import shutil\n",
    "\n",
    "def f2f(scr, dst='/tmp/anomaly'):\n",
    "    for jf in glob.iglob(os.path.join(scr,\"*.png\")):\n",
    "        shutil.copy(jf, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa0a5309",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:43.056679Z",
     "iopub.status.busy": "2022-02-22T19:09:43.055964Z",
     "iopub.status.idle": "2022-02-22T19:09:43.058974Z",
     "shell.execute_reply": "2022-02-22T19:09:43.059389Z",
     "shell.execute_reply.started": "2022-02-22T19:03:06.804086Z"
    },
    "papermill": {
     "duration": 0.035914,
     "end_time": "2022-02-22T19:09:43.059506",
     "exception": false,
     "start_time": "2022-02-22T19:09:43.023592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nf2f(di+\"COVID\" )\\nf2f(di+\\'Lung_Opacity\\')\\nf2f(di+\"Viral Pneumonia\")\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "f2f(di+\"COVID\" )\n",
    "f2f(di+'Lung_Opacity')\n",
    "f2f(di+\"Viral Pneumonia\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7a918a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:43.115230Z",
     "iopub.status.busy": "2022-02-22T19:09:43.114474Z",
     "iopub.status.idle": "2022-02-22T19:09:43.762957Z",
     "shell.execute_reply": "2022-02-22T19:09:43.762472Z",
     "shell.execute_reply.started": "2022-02-22T19:03:06.817284Z"
    },
    "papermill": {
     "duration": 0.677083,
     "end_time": "2022-02-22T19:09:43.763084",
     "exception": false,
     "start_time": "2022-02-22T19:09:43.086001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir /tmp/normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97bbf575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:09:43.821617Z",
     "iopub.status.busy": "2022-02-22T19:09:43.820981Z",
     "iopub.status.idle": "2022-02-22T19:10:50.877823Z",
     "shell.execute_reply": "2022-02-22T19:10:50.877112Z",
     "shell.execute_reply.started": "2022-02-22T19:03:07.497552Z"
    },
    "papermill": {
     "duration": 67.088242,
     "end_time": "2022-02-22T19:10:50.877970",
     "exception": false,
     "start_time": "2022-02-22T19:09:43.789728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "di = \"../input/covid19-radiography-database/COVID-19_Radiography_Dataset/\"\n",
    "f2f(di+\"Normal\", \"/tmp/normal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d969eef",
   "metadata": {
    "papermill": {
     "duration": 0.026518,
     "end_time": "2022-02-22T19:10:50.931951",
     "exception": false,
     "start_time": "2022-02-22T19:10:50.905433",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next we'll create a `dataset` of all the normal samples to train the *anomaly detection system*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6bfc75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:50.991326Z",
     "iopub.status.busy": "2022-02-22T19:10:50.990762Z",
     "iopub.status.idle": "2022-02-22T19:10:53.946800Z",
     "shell.execute_reply": "2022-02-22T19:10:53.946160Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.083891Z"
    },
    "papermill": {
     "duration": 2.988629,
     "end_time": "2022-02-22T19:10:53.946958",
     "exception": false,
     "start_time": "2022-02-22T19:10:50.958329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10192 files belonging to 1 classes.\n",
      "Using 9173 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 19:10:51.304280: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:51.400611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:51.401410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:51.406546: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-22 19:10:51.407598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:51.408574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:51.409218: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:53.345624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:53.346429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:53.347067: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-02-22 19:10:53.347700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10192 files belonging to 1 classes.\n",
      "Using 1019 files for validation.\n"
     ]
    }
   ],
   "source": [
    "encotds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/normal\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"training\", interpolation = \"bicubic\")\n",
    "\n",
    "encovds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/normal\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"validation\", interpolation = \"bicubic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8af7c86",
   "metadata": {
    "papermill": {
     "duration": 0.027683,
     "end_time": "2022-02-22T19:10:54.003170",
     "exception": false,
     "start_time": "2022-02-22T19:10:53.975487",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, the dataset of all the anomalous samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "511043eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.066349Z",
     "iopub.status.busy": "2022-02-22T19:10:54.065507Z",
     "iopub.status.idle": "2022-02-22T19:10:54.068556Z",
     "shell.execute_reply": "2022-02-22T19:10:54.068973Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.601784Z"
    },
    "papermill": {
     "duration": 0.038084,
     "end_time": "2022-02-22T19:10:54.069108",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.031024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nanoTds = tf.keras.preprocessing.image_dataset_from_directory(\\n    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \\n    image_size = (224, 224), shuffle = True, seed = 42, \\n    validation_split = 0.1, subset = \"training\", interpolation = \"bicubic\")\\n\\nanoVds = tf.keras.preprocessing.image_dataset_from_directory(\\n    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \\n    image_size = (224, 224), shuffle = True, seed = 42, \\n    validation_split = 0.1, subset = \"validation\", interpolation = \"bicubic\")\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "anoTds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"training\", interpolation = \"bicubic\")\n",
    "\n",
    "anoVds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"/tmp/anomaly\", labels = None, color_mode = \"rgb\", batch_size = 32, \n",
    "    image_size = (224, 224), shuffle = True, seed = 42, \n",
    "    validation_split = 0.1, subset = \"validation\", interpolation = \"bicubic\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91ae8a7",
   "metadata": {
    "papermill": {
     "duration": 0.028831,
     "end_time": "2022-02-22T19:10:54.127927",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.099096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b9a78e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.192694Z",
     "iopub.status.busy": "2022-02-22T19:10:54.191996Z",
     "iopub.status.idle": "2022-02-22T19:10:54.194177Z",
     "shell.execute_reply": "2022-02-22T19:10:54.194638Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.609986Z"
    },
    "papermill": {
     "duration": 0.03824,
     "end_time": "2022-02-22T19:10:54.194761",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.156521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True):\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2D(filters=f1, kernel_size=1, padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2D(filters=f2, kernel_size=f, padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2D(filters=f3, kernel_size=1, padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    \n",
    "    X = tf.keras.layers.Add()([X_skip, X])\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90f2acab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.260448Z",
     "iopub.status.busy": "2022-02-22T19:10:54.259654Z",
     "iopub.status.idle": "2022-02-22T19:10:54.261611Z",
     "shell.execute_reply": "2022-02-22T19:10:54.261978Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.621914Z"
    },
    "papermill": {
     "duration": 0.038702,
     "end_time": "2022-02-22T19:10:54.262134",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.223432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_block(X, f, filters, s=2, training=True):\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2D(filters = f1, kernel_size = 1, strides = (s, s), padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2D(filters = f2, kernel_size = f, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X) \n",
    "    \n",
    "    X = Conv2D(filters = f3, kernel_size = 1, strides = (1, 1), padding='valid')(X)\n",
    "    X = BatchNormalization()(X, training = training)\n",
    "    \n",
    "    X_skip = Conv2D(filters = f3, kernel_size = 1, strides=(s,s), padding='valid')(X_skip)\n",
    "    X_skip = BatchNormalization()(X_skip, training = training)\n",
    "    \n",
    "    X = Add()([X, X_skip])\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddbc01d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.330033Z",
     "iopub.status.busy": "2022-02-22T19:10:54.329284Z",
     "iopub.status.idle": "2022-02-22T19:10:54.331658Z",
     "shell.execute_reply": "2022-02-22T19:10:54.331216Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.633438Z"
    },
    "papermill": {
     "duration": 0.040899,
     "end_time": "2022-02-22T19:10:54.331765",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.290866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Trans_conv_block(X, f, filters, s=2, training=True):\n",
    "    \n",
    "    f1, f2, f3 = filters\n",
    "    X_skip = X\n",
    "    \n",
    "    X = Conv2DTranspose(filters = f1, kernel_size = 1, strides = (s, s), padding='valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    X = Conv2DTranspose(filters = f2, kernel_size = f, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = tf.keras.activations.relu(X) \n",
    "    \n",
    "    X = Conv2DTranspose(filters = f3, kernel_size = 1, strides = (1, 1), padding='same')(X)\n",
    "    X = BatchNormalization()(X, training = training)\n",
    "    \n",
    "    X_skip = Conv2DTranspose(filters = f3, kernel_size = 1, strides=(s,s), padding='valid')(X_skip)\n",
    "    X_skip = BatchNormalization()(X_skip, training = training)\n",
    "    \n",
    "    X = Add()([X, X_skip])\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fad32ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.396272Z",
     "iopub.status.busy": "2022-02-22T19:10:54.395543Z",
     "iopub.status.idle": "2022-02-22T19:10:54.397993Z",
     "shell.execute_reply": "2022-02-22T19:10:54.397546Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.647544Z"
    },
    "papermill": {
     "duration": 0.038071,
     "end_time": "2022-02-22T19:10:54.398102",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.360031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def enco(input_shape=(224,224,3)):\n",
    "    \n",
    "    X_inp = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    X = Conv2D(64, (3,3), strides = (2,2))(X_inp)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = tf.keras.activations.relu(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    X = conv_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "    X = conv_block(X, 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    \n",
    "    model = tf.keras.Model(inputs=X_inp,outputs=X)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29e16633",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.460612Z",
     "iopub.status.busy": "2022-02-22T19:10:54.460085Z",
     "iopub.status.idle": "2022-02-22T19:10:54.864842Z",
     "shell.execute_reply": "2022-02-22T19:10:54.865445Z",
     "shell.execute_reply.started": "2022-02-22T19:03:19.660935Z"
    },
    "papermill": {
     "duration": 0.437204,
     "end_time": "2022-02-22T19:10:54.865645",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.428441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 28, 28, 512)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 111, 111, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 111, 111, 64) 256         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu (TFOpLambda)         (None, 111, 111, 64) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 55, 55, 64)   0           tf.nn.relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 55, 55, 64)   4160        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 55, 55, 64)   256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_1 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 55, 55, 64)   36928       tf.nn.relu_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 55, 55, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_2 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 55, 55, 256)  16640       tf.nn.relu_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 55, 55, 256)  16640       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 55, 55, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 55, 55, 256)  1024        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 55, 55, 256)  0           batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_3 (TFOpLambda)       (None, 55, 55, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 55, 55, 64)   16448       tf.nn.relu_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 55, 55, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_4 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 55, 55, 64)   36928       tf.nn.relu_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 55, 55, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_5 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 55, 55, 256)  16640       tf.nn.relu_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 55, 55, 256)  1024        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 55, 55, 256)  0           tf.nn.relu_3[0][0]               \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_6 (TFOpLambda)       (None, 55, 55, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 55, 55, 64)   16448       tf.nn.relu_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 55, 55, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_7 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 55, 55, 64)   36928       tf.nn.relu_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 55, 55, 64)   256         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_8 (TFOpLambda)       (None, 55, 55, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 55, 55, 256)  16640       tf.nn.relu_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 55, 55, 256)  1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 55, 55, 256)  0           tf.nn.relu_6[0][0]               \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_9 (TFOpLambda)       (None, 55, 55, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 28, 28, 128)  32896       tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 28, 28, 128)  512         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_10 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 28, 28, 128)  147584      tf.nn.relu_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 28, 28, 128)  512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_11 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 28, 28, 512)  66048       tf.nn.relu_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 28, 28, 512)  131584      tf.nn.relu_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 28, 28, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 28, 28, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 28, 28, 512)  0           batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_12 (TFOpLambda)      (None, 28, 28, 512)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 28, 28, 128)  65664       tf.nn.relu_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 28, 28, 128)  512         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_13 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 28, 28, 128)  147584      tf.nn.relu_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 28, 28, 128)  512         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_14 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 28, 28, 512)  66048       tf.nn.relu_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 28, 28, 512)  2048        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 28, 28, 512)  0           tf.nn.relu_12[0][0]              \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_15 (TFOpLambda)      (None, 28, 28, 512)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 28, 28, 128)  65664       tf.nn.relu_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 28, 28, 128)  512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_16 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 28, 28, 128)  147584      tf.nn.relu_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 28, 28, 128)  512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_17 (TFOpLambda)      (None, 28, 28, 128)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 28, 28, 512)  66048       tf.nn.relu_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 28, 28, 512)  2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 28, 28, 512)  0           tf.nn.relu_15[0][0]              \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_18 (TFOpLambda)      (None, 28, 28, 512)  0           add_5[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,170,048\n",
      "Trainable params: 1,161,472\n",
      "Non-trainable params: 8,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = enco()\n",
    "print(mod.output.shape)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333339ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:54.932696Z",
     "iopub.status.busy": "2022-02-22T19:10:54.931899Z",
     "iopub.status.idle": "2022-02-22T19:10:54.936024Z",
     "shell.execute_reply": "2022-02-22T19:10:54.935635Z",
     "shell.execute_reply.started": "2022-02-22T19:03:20.048737Z"
    },
    "papermill": {
     "duration": 0.040585,
     "end_time": "2022-02-22T19:10:54.936137",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.895552",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deco(input_shape=(28,28,512)):\n",
    "    \n",
    "    X_inp = tf.keras.Input(shape=input_shape)\n",
    "    \n",
    "    X = Trans_conv_block(X_inp, 3, [256, 256, 128], s=2, training=True)\n",
    "    X = identity_block(X, 3, [256, 128, 128])\n",
    "    X = identity_block(X, 3, [256, 128, 128])\n",
    "    \n",
    "    X = Trans_conv_block(X, 3, [128, 64, 64], s=1, training=True)\n",
    "    X = identity_block(X, 3, [128, 64, 64])\n",
    "    X = identity_block(X, 3, [128, 64, 64])\n",
    "    \n",
    "    #X = Conv2DTranspose(64, (7,7), strides = (2,2), padding='valid')(X)\n",
    "    X = Trans_conv_block(X, 3, [64, 32, 32], s=2, training=True)\n",
    "    X = identity_block(X, 3, [64, 32, 32])\n",
    "    X = identity_block(X, 3, [64, 32, 32])\n",
    "    \n",
    "    X = Trans_conv_block(X, 11, [64, 32, 32], s=2, training=True)\n",
    "    X = Conv2D(filters=3 , kernel_size = 1, strides = 1, padding='valid')(X)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=X_inp,outputs=X)\n",
    "    \n",
    "    return model   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "583e636e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:55.004215Z",
     "iopub.status.busy": "2022-02-22T19:10:54.999416Z",
     "iopub.status.idle": "2022-02-22T19:10:55.806583Z",
     "shell.execute_reply": "2022-02-22T19:10:55.805869Z",
     "shell.execute_reply.started": "2022-02-22T19:03:20.061116Z"
    },
    "papermill": {
     "duration": 0.841858,
     "end_time": "2022-02-22T19:10:55.806767",
     "exception": false,
     "start_time": "2022-02-22T19:10:54.964909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 224, 224, 3)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 28, 28, 512) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 56, 56, 256)  131328      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 56, 56, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_19 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 56, 56, 256)  590080      tf.nn.relu_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 56, 56, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_20 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 56, 56, 128)  32896       tf.nn.relu_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 56, 56, 128)  65664       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 56, 56, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 56, 56, 128)  512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 56, 56, 128)  0           batch_normalization_23[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_21 (TFOpLambda)      (None, 56, 56, 128)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 56, 56, 256)  33024       tf.nn.relu_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 56, 56, 256)  1024        conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_22 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 56, 56, 128)  295040      tf.nn.relu_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 56, 56, 128)  512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_23 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 56, 56, 128)  16512       tf.nn.relu_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 56, 56, 128)  512         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 56, 56, 128)  0           tf.nn.relu_21[0][0]              \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_24 (TFOpLambda)      (None, 56, 56, 128)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 56, 56, 256)  33024       tf.nn.relu_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 56, 56, 256)  1024        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_25 (TFOpLambda)      (None, 56, 56, 256)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 56, 56, 128)  295040      tf.nn.relu_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 56, 56, 128)  512         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_26 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 56, 56, 128)  16512       tf.nn.relu_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 56, 56, 128)  512         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 56, 56, 128)  0           tf.nn.relu_24[0][0]              \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_27 (TFOpLambda)      (None, 56, 56, 128)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 56, 56, 128)  16512       tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 56, 56, 128)  512         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_28 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 56, 56, 64)   73792       tf.nn.relu_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 56, 56, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_29 (TFOpLambda)      (None, 56, 56, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 56, 56, 64)   4160        tf.nn.relu_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 56, 56, 64)   8256        tf.nn.relu_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 56, 56, 64)   256         conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 56, 56, 64)   256         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 56, 56, 64)   0           batch_normalization_33[0][0]     \n",
      "                                                                 batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_30 (TFOpLambda)      (None, 56, 56, 64)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 56, 56, 128)  8320        tf.nn.relu_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 56, 56, 128)  512         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_31 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 56, 56, 64)   73792       tf.nn.relu_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 56, 56, 64)   256         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_32 (TFOpLambda)      (None, 56, 56, 64)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 56, 56, 64)   4160        tf.nn.relu_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 56, 56, 64)   256         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 56, 56, 64)   0           tf.nn.relu_30[0][0]              \n",
      "                                                                 batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_33 (TFOpLambda)      (None, 56, 56, 64)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 56, 56, 128)  8320        tf.nn.relu_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 56, 56, 128)  512         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_34 (TFOpLambda)      (None, 56, 56, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 56, 56, 64)   73792       tf.nn.relu_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 56, 56, 64)   256         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_35 (TFOpLambda)      (None, 56, 56, 64)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 56, 56, 64)   4160        tf.nn.relu_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 56, 56, 64)   256         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 56, 56, 64)   0           tf.nn.relu_33[0][0]              \n",
      "                                                                 batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_36 (TFOpLambda)      (None, 56, 56, 64)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 112, 112, 64) 4160        tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 112, 112, 64) 256         conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_37 (TFOpLambda)      (None, 112, 112, 64) 0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 112, 112, 32) 18464       tf.nn.relu_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 112, 112, 32) 128         conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_38 (TFOpLambda)      (None, 112, 112, 32) 0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DTran (None, 112, 112, 32) 1056        tf.nn.relu_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DTran (None, 112, 112, 32) 2080        tf.nn.relu_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 112, 112, 32) 128         conv2d_transpose_10[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 112, 112, 32) 128         conv2d_transpose_11[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 112, 112, 32) 0           batch_normalization_43[0][0]     \n",
      "                                                                 batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_39 (TFOpLambda)      (None, 112, 112, 32) 0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 112, 112, 64) 2112        tf.nn.relu_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 112, 112, 64) 256         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_40 (TFOpLambda)      (None, 112, 112, 64) 0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 112, 112, 32) 18464       tf.nn.relu_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 112, 112, 32) 128         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_41 (TFOpLambda)      (None, 112, 112, 32) 0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 112, 112, 32) 1056        tf.nn.relu_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 112, 112, 32) 128         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 112, 112, 32) 0           tf.nn.relu_39[0][0]              \n",
      "                                                                 batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_42 (TFOpLambda)      (None, 112, 112, 32) 0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 112, 112, 64) 2112        tf.nn.relu_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 112, 112, 64) 256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_43 (TFOpLambda)      (None, 112, 112, 64) 0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 112, 112, 32) 18464       tf.nn.relu_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 112, 112, 32) 128         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_44 (TFOpLambda)      (None, 112, 112, 32) 0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 112, 112, 32) 1056        tf.nn.relu_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 112, 112, 32) 128         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 112, 112, 32) 0           tf.nn.relu_42[0][0]              \n",
      "                                                                 batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_45 (TFOpLambda)      (None, 112, 112, 32) 0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_12 (Conv2DTran (None, 224, 224, 64) 2112        tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 224, 224, 64) 256         conv2d_transpose_12[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_46 (TFOpLambda)      (None, 224, 224, 64) 0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_13 (Conv2DTran (None, 224, 224, 32) 247840      tf.nn.relu_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_13[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_47 (TFOpLambda)      (None, 224, 224, 32) 0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_14 (Conv2DTran (None, 224, 224, 32) 1056        tf.nn.relu_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DTran (None, 224, 224, 32) 1056        tf.nn.relu_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_14[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 224, 224, 32) 128         conv2d_transpose_15[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 224, 224, 32) 0           batch_normalization_53[0][0]     \n",
      "                                                                 batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.nn.relu_48 (TFOpLambda)      (None, 224, 224, 32) 0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 224, 224, 3)  99          tf.nn.relu_48[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,118,371\n",
      "Trainable params: 2,111,971\n",
      "Non-trainable params: 6,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod = deco()\n",
    "print(mod.output.shape)\n",
    "mod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efe88f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:55.913182Z",
     "iopub.status.busy": "2022-02-22T19:10:55.912437Z",
     "iopub.status.idle": "2022-02-22T19:10:55.915951Z",
     "shell.execute_reply": "2022-02-22T19:10:55.916898Z",
     "shell.execute_reply.started": "2022-02-22T19:03:20.731049Z"
    },
    "papermill": {
     "duration": 0.061037,
     "end_time": "2022-02-22T19:10:55.917067",
     "exception": false,
     "start_time": "2022-02-22T19:10:55.856030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Autoencoder(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = enco(input_shape=(224,224,3))\n",
    "        self.decoder = deco(input_shape=(28,28,512)) \n",
    "        \n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83faddf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:56.020337Z",
     "iopub.status.busy": "2022-02-22T19:10:56.019510Z",
     "iopub.status.idle": "2022-02-22T19:10:57.026328Z",
     "shell.execute_reply": "2022-02-22T19:10:57.025719Z",
     "shell.execute_reply.started": "2022-02-22T19:03:20.739625Z"
    },
    "papermill": {
     "duration": 1.060761,
     "end_time": "2022-02-22T19:10:57.026471",
     "exception": false,
     "start_time": "2022-02-22T19:10:55.965710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n",
    "autoencoder.compile(optimizer='adam', loss = 'MeanSquaredError')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96039700",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:57.109231Z",
     "iopub.status.busy": "2022-02-22T19:10:57.096722Z",
     "iopub.status.idle": "2022-02-22T19:10:57.132233Z",
     "shell.execute_reply": "2022-02-22T19:10:57.131767Z",
     "shell.execute_reply.started": "2022-02-22T19:03:21.698186Z"
    },
    "papermill": {
     "duration": 0.073434,
     "end_time": "2022-02-22T19:10:57.132384",
     "exception": false,
     "start_time": "2022-02-22T19:10:57.058950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tds = encotds.map(lambda x : (x,x))\n",
    "vds = encovds.map(lambda x : (x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7fc463",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:57.205544Z",
     "iopub.status.busy": "2022-02-22T19:10:57.204639Z",
     "iopub.status.idle": "2022-02-22T19:10:57.206671Z",
     "shell.execute_reply": "2022-02-22T19:10:57.207131Z",
     "shell.execute_reply.started": "2022-02-22T19:03:21.737876Z"
    },
    "papermill": {
     "duration": 0.040844,
     "end_time": "2022-02-22T19:10:57.207275",
     "exception": false,
     "start_time": "2022-02-22T19:10:57.166431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = \"Checkpoint/cp.ckpt\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3d9b85f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-22T19:10:57.350857Z",
     "iopub.status.busy": "2022-02-22T19:10:57.350094Z",
     "iopub.status.idle": "2022-02-23T01:16:48.786305Z",
     "shell.execute_reply": "2022-02-23T01:16:48.786789Z",
     "shell.execute_reply.started": "2022-02-22T19:03:21.744081Z"
    },
    "papermill": {
     "duration": 21951.531084,
     "end_time": "2022-02-23T01:16:48.787035",
     "exception": false,
     "start_time": "2022-02-22T19:10:57.255951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 19:10:57.385928: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 19:11:03.660435: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287/287 [==============================] - 147s 454ms/step - loss: 19382.1543 - val_loss: 17371.5215\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 17371.52148, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-22 19:13:37.854507: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 13753.5361 - val_loss: 10255.3574\n",
      "\n",
      "Epoch 00002: val_loss improved from 17371.52148 to 10255.35742, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150\n",
      "287/287 [==============================] - 125s 433ms/step - loss: 6589.3359 - val_loss: 3823.5215\n",
      "\n",
      "Epoch 00003: val_loss improved from 10255.35742 to 3823.52148, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150\n",
      "287/287 [==============================] - 125s 433ms/step - loss: 2041.1158 - val_loss: 914.6367\n",
      "\n",
      "Epoch 00004: val_loss improved from 3823.52148 to 914.63666, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150\n",
      "287/287 [==============================] - 126s 434ms/step - loss: 409.1430 - val_loss: 175.9470\n",
      "\n",
      "Epoch 00005: val_loss improved from 914.63666 to 175.94704, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150\n",
      "287/287 [==============================] - 126s 434ms/step - loss: 93.3612 - val_loss: 68.6626\n",
      "\n",
      "Epoch 00006: val_loss improved from 175.94704 to 68.66264, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 57.9504 - val_loss: 50.5541\n",
      "\n",
      "Epoch 00007: val_loss improved from 68.66264 to 50.55405, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 50.2373 - val_loss: 46.1107\n",
      "\n",
      "Epoch 00008: val_loss improved from 50.55405 to 46.11071, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 46.4704 - val_loss: 47.1151\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 46.11071\n",
      "Epoch 10/150\n",
      "287/287 [==============================] - 125s 433ms/step - loss: 45.8654 - val_loss: 51.6090\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 46.11071\n",
      "Epoch 11/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 42.4052 - val_loss: 38.7534\n",
      "\n",
      "Epoch 00011: val_loss improved from 46.11071 to 38.75341, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 43.5259 - val_loss: 45.0244\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 38.75341\n",
      "Epoch 13/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 42.2725 - val_loss: 47.3058\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 38.75341\n",
      "Epoch 14/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 38.4785 - val_loss: 41.0804\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 38.75341\n",
      "Epoch 15/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 36.3464 - val_loss: 34.0389\n",
      "\n",
      "Epoch 00015: val_loss improved from 38.75341 to 34.03891, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 37.8327 - val_loss: 40.8041\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 34.03891\n",
      "Epoch 17/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 34.1511 - val_loss: 29.3780\n",
      "\n",
      "Epoch 00017: val_loss improved from 34.03891 to 29.37803, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 32.9623 - val_loss: 28.7569\n",
      "\n",
      "Epoch 00018: val_loss improved from 29.37803 to 28.75690, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 33.5565 - val_loss: 33.7567\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 28.75690\n",
      "Epoch 20/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 31.4749 - val_loss: 39.2412\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 28.75690\n",
      "Epoch 21/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 31.8831 - val_loss: 30.3549\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 28.75690\n",
      "Epoch 22/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 29.6141 - val_loss: 28.1791\n",
      "\n",
      "Epoch 00022: val_loss improved from 28.75690 to 28.17914, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 31.8277 - val_loss: 26.1459\n",
      "\n",
      "Epoch 00023: val_loss improved from 28.17914 to 26.14591, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 26.7329 - val_loss: 24.9974\n",
      "\n",
      "Epoch 00024: val_loss improved from 26.14591 to 24.99744, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 29.0805 - val_loss: 34.6858\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 24.99744\n",
      "Epoch 26/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 27.2881 - val_loss: 30.9247\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 24.99744\n",
      "Epoch 27/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 27.8448 - val_loss: 31.2354\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 24.99744\n",
      "Epoch 28/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 24.3473 - val_loss: 23.9346\n",
      "\n",
      "Epoch 00028: val_loss improved from 24.99744 to 23.93460, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 22.9176 - val_loss: 22.2133\n",
      "\n",
      "Epoch 00029: val_loss improved from 23.93460 to 22.21333, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 20.7087 - val_loss: 21.6432\n",
      "\n",
      "Epoch 00030: val_loss improved from 22.21333 to 21.64321, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 21.5801 - val_loss: 20.4791\n",
      "\n",
      "Epoch 00031: val_loss improved from 21.64321 to 20.47906, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 21.2440 - val_loss: 19.5716\n",
      "\n",
      "Epoch 00032: val_loss improved from 20.47906 to 19.57161, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 21.0190 - val_loss: 26.1874\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 19.57161\n",
      "Epoch 34/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 22.0629 - val_loss: 24.6805\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 19.57161\n",
      "Epoch 35/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 19.5454 - val_loss: 22.8337\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 19.57161\n",
      "Epoch 36/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 17.5979 - val_loss: 24.4362\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 19.57161\n",
      "Epoch 37/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 17.9410 - val_loss: 21.6164\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 19.57161\n",
      "Epoch 38/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 19.6296 - val_loss: 17.5626\n",
      "\n",
      "Epoch 00038: val_loss improved from 19.57161 to 17.56260, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 19.7045 - val_loss: 16.9750\n",
      "\n",
      "Epoch 00039: val_loss improved from 17.56260 to 16.97498, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 17.7141 - val_loss: 18.5296\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 16.97498\n",
      "Epoch 41/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 18.7231 - val_loss: 21.7257\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 16.97498\n",
      "Epoch 42/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 16.8666 - val_loss: 18.3297\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 16.97498\n",
      "Epoch 43/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 15.8146 - val_loss: 16.2395\n",
      "\n",
      "Epoch 00043: val_loss improved from 16.97498 to 16.23948, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 15.2942 - val_loss: 21.7095\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 16.23948\n",
      "Epoch 45/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 15.9106 - val_loss: 15.7970\n",
      "\n",
      "Epoch 00045: val_loss improved from 16.23948 to 15.79700, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 15.3143 - val_loss: 16.3930\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 15.79700\n",
      "Epoch 47/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 14.6418 - val_loss: 16.6731\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 15.79700\n",
      "Epoch 48/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 15.2361 - val_loss: 17.2985\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 15.79700\n",
      "Epoch 49/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 14.8107 - val_loss: 18.1959\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 15.79700\n",
      "Epoch 50/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 14.8039 - val_loss: 15.7280\n",
      "\n",
      "Epoch 00050: val_loss improved from 15.79700 to 15.72799, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 14.2735 - val_loss: 18.3074\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 15.72799\n",
      "Epoch 52/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 14.6491 - val_loss: 16.4634\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 15.72799\n",
      "Epoch 53/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 16.1403 - val_loss: 15.6935\n",
      "\n",
      "Epoch 00053: val_loss improved from 15.72799 to 15.69350, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 14.2505 - val_loss: 16.6022\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 15.69350\n",
      "Epoch 55/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 13.9416 - val_loss: 16.5188\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 15.69350\n",
      "Epoch 56/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 14.0699 - val_loss: 16.2926\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 15.69350\n",
      "Epoch 57/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 13.3180 - val_loss: 14.6562\n",
      "\n",
      "Epoch 00057: val_loss improved from 15.69350 to 14.65618, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 13.2969 - val_loss: 14.7414\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 14.65618\n",
      "Epoch 59/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 12.6529 - val_loss: 17.0573\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 14.65618\n",
      "Epoch 60/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 13.4805 - val_loss: 13.8179\n",
      "\n",
      "Epoch 00060: val_loss improved from 14.65618 to 13.81786, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.7837 - val_loss: 16.5352\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 13.81786\n",
      "Epoch 62/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 12.6454 - val_loss: 13.4370\n",
      "\n",
      "Epoch 00062: val_loss improved from 13.81786 to 13.43701, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 13.0211 - val_loss: 16.8185\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 13.43701\n",
      "Epoch 64/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 13.2468 - val_loss: 26.8328\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 13.43701\n",
      "Epoch 65/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.5912 - val_loss: 16.0924\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 13.43701\n",
      "Epoch 66/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 13.1581 - val_loss: 16.4813\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 13.43701\n",
      "Epoch 67/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 11.7159 - val_loss: 14.9948\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 13.43701\n",
      "Epoch 68/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 12.3788 - val_loss: 14.4647\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 13.43701\n",
      "Epoch 69/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.5954 - val_loss: 16.3815\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 13.43701\n",
      "Epoch 70/150\n",
      "287/287 [==============================] - 130s 450ms/step - loss: 12.0995 - val_loss: 13.8731\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 13.43701\n",
      "Epoch 71/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.7301 - val_loss: 13.9101\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 13.43701\n",
      "Epoch 72/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.7750 - val_loss: 15.0410\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 13.43701\n",
      "Epoch 73/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 11.5222 - val_loss: 17.4077\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 13.43701\n",
      "Epoch 74/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 11.8483 - val_loss: 13.9436\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 13.43701\n",
      "Epoch 75/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.8070 - val_loss: 15.8429\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 13.43701\n",
      "Epoch 76/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 12.7798 - val_loss: 13.5028\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 13.43701\n",
      "Epoch 77/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.7218 - val_loss: 16.8800\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 13.43701\n",
      "Epoch 78/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 12.1045 - val_loss: 16.7559\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 13.43701\n",
      "Epoch 79/150\n",
      "287/287 [==============================] - 126s 439ms/step - loss: 11.0245 - val_loss: 13.3087\n",
      "\n",
      "Epoch 00079: val_loss improved from 13.43701 to 13.30867, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 10.6871 - val_loss: 13.4949\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 13.30867\n",
      "Epoch 81/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 11.3596 - val_loss: 19.6165\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 13.30867\n",
      "Epoch 82/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 10.6531 - val_loss: 11.8963\n",
      "\n",
      "Epoch 00082: val_loss improved from 13.30867 to 11.89628, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 10.3383 - val_loss: 12.3326\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 11.89628\n",
      "Epoch 84/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 12.3043 - val_loss: 15.2075\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 11.89628\n",
      "Epoch 85/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 10.7210 - val_loss: 13.0281\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 11.89628\n",
      "Epoch 86/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 10.3620 - val_loss: 15.6294\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 11.89628\n",
      "Epoch 87/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 10.2656 - val_loss: 15.0346\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 11.89628\n",
      "Epoch 88/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.8846 - val_loss: 12.1277\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 11.89628\n",
      "Epoch 89/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 11.1084 - val_loss: 13.8981\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 11.89628\n",
      "Epoch 90/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.9886 - val_loss: 12.5640\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 11.89628\n",
      "Epoch 91/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.4477 - val_loss: 15.4017\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 11.89628\n",
      "Epoch 92/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 9.8466 - val_loss: 12.4967\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 11.89628\n",
      "Epoch 93/150\n",
      "287/287 [==============================] - 130s 450ms/step - loss: 10.0985 - val_loss: 12.7919\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 11.89628\n",
      "Epoch 94/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 10.6122 - val_loss: 13.5331\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 11.89628\n",
      "Epoch 95/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.4803 - val_loss: 13.7567\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 11.89628\n",
      "Epoch 96/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.4995 - val_loss: 12.7223\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 11.89628\n",
      "Epoch 97/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.8396 - val_loss: 14.4855\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 11.89628\n",
      "Epoch 98/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 10.3786 - val_loss: 13.1743\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 11.89628\n",
      "Epoch 99/150\n",
      "287/287 [==============================] - 129s 449ms/step - loss: 9.6404 - val_loss: 11.7253\n",
      "\n",
      "Epoch 00099: val_loss improved from 11.89628 to 11.72530, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.0637 - val_loss: 13.7229\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 11.72530\n",
      "Epoch 101/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 9.7702 - val_loss: 11.2006\n",
      "\n",
      "Epoch 00101: val_loss improved from 11.72530 to 11.20062, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 102/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.9666 - val_loss: 20.3750\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 11.20062\n",
      "Epoch 103/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 9.6287 - val_loss: 12.3278\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 11.20062\n",
      "Epoch 104/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 9.2784 - val_loss: 12.5470\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 11.20062\n",
      "Epoch 105/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.2727 - val_loss: 12.2114\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 11.20062\n",
      "Epoch 106/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 8.4635 - val_loss: 17.8117\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 11.20062\n",
      "Epoch 107/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 9.1985 - val_loss: 16.6880\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 11.20062\n",
      "Epoch 108/150\n",
      "287/287 [==============================] - 125s 436ms/step - loss: 9.1762 - val_loss: 12.3476\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 11.20062\n",
      "Epoch 109/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.3709 - val_loss: 11.9770\n",
      "\n",
      "Epoch 00109: val_loss did not improve from 11.20062\n",
      "Epoch 110/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.0242 - val_loss: 13.6239\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 11.20062\n",
      "Epoch 111/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.5011 - val_loss: 10.5071\n",
      "\n",
      "Epoch 00111: val_loss improved from 11.20062 to 10.50713, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 9.0074 - val_loss: 11.1613\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 10.50713\n",
      "Epoch 113/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.2148 - val_loss: 12.1129\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 10.50713\n",
      "Epoch 114/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.5071 - val_loss: 13.5495\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 10.50713\n",
      "Epoch 115/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.5943 - val_loss: 11.8073\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 10.50713\n",
      "Epoch 116/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.2971 - val_loss: 12.4941\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 10.50713\n",
      "Epoch 117/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.5816 - val_loss: 11.2047\n",
      "\n",
      "Epoch 00117: val_loss did not improve from 10.50713\n",
      "Epoch 118/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.7422 - val_loss: 16.0558\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 10.50713\n",
      "Epoch 119/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.4758 - val_loss: 10.5484\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 10.50713\n",
      "Epoch 120/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.2262 - val_loss: 12.3946\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 10.50713\n",
      "Epoch 121/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.9034 - val_loss: 12.2152\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 10.50713\n",
      "Epoch 122/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.5631 - val_loss: 11.5891\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 10.50713\n",
      "Epoch 123/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 9.0860 - val_loss: 10.4713\n",
      "\n",
      "Epoch 00123: val_loss improved from 10.50713 to 10.47127, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 8.2567 - val_loss: 14.9509\n",
      "\n",
      "Epoch 00124: val_loss did not improve from 10.47127\n",
      "Epoch 125/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.6698 - val_loss: 10.4365\n",
      "\n",
      "Epoch 00125: val_loss improved from 10.47127 to 10.43646, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 8.2966 - val_loss: 13.8034\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 10.43646\n",
      "Epoch 127/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.4183 - val_loss: 10.8338\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 10.43646\n",
      "Epoch 128/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.7702 - val_loss: 11.0595\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 10.43646\n",
      "Epoch 129/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 7.9691 - val_loss: 15.2310\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 10.43646\n",
      "Epoch 130/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.9472 - val_loss: 11.7616\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 10.43646\n",
      "Epoch 131/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.3948 - val_loss: 11.3946\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 10.43646\n",
      "Epoch 132/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.6053 - val_loss: 11.8334\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 10.43646\n",
      "Epoch 133/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.1945 - val_loss: 11.1087\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 10.43646\n",
      "Epoch 134/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 7.8577 - val_loss: 10.8477\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 10.43646\n",
      "Epoch 135/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.7362 - val_loss: 13.8185\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 10.43646\n",
      "Epoch 136/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.6961 - val_loss: 11.6014\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 10.43646\n",
      "Epoch 137/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.6786 - val_loss: 11.3465\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 10.43646\n",
      "Epoch 138/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.4124 - val_loss: 10.2071\n",
      "\n",
      "Epoch 00138: val_loss improved from 10.43646 to 10.20713, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/150\n",
      "287/287 [==============================] - 126s 435ms/step - loss: 8.1208 - val_loss: 11.9683\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 10.20713\n",
      "Epoch 140/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 8.0051 - val_loss: 13.3897\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 10.20713\n",
      "Epoch 141/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 7.7831 - val_loss: 11.0878\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 10.20713\n",
      "Epoch 142/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.1117 - val_loss: 13.0699\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 10.20713\n",
      "Epoch 143/150\n",
      "287/287 [==============================] - 126s 437ms/step - loss: 7.6716 - val_loss: 11.0614\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 10.20713\n",
      "Epoch 144/150\n",
      "287/287 [==============================] - 125s 436ms/step - loss: 7.2804 - val_loss: 10.0071\n",
      "\n",
      "Epoch 00144: val_loss improved from 10.20713 to 10.00709, saving model to Checkpoint/cp.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "287/287 [==============================] - 130s 450ms/step - loss: 7.5575 - val_loss: 11.0086\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 10.00709\n",
      "Epoch 146/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.3529 - val_loss: 14.1253\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 10.00709\n",
      "Epoch 147/150\n",
      "287/287 [==============================] - 125s 434ms/step - loss: 8.3371 - val_loss: 13.6806\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 10.00709\n",
      "Epoch 148/150\n",
      "287/287 [==============================] - 126s 436ms/step - loss: 7.6299 - val_loss: 13.1380\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 10.00709\n",
      "Epoch 149/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 7.1591 - val_loss: 10.0317\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 10.00709\n",
      "Epoch 150/150\n",
      "287/287 [==============================] - 125s 435ms/step - loss: 8.1099 - val_loss: 12.5485\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 10.00709\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(tds,\n",
    "                epochs=150,\n",
    "                shuffle=True,\n",
    "                callbacks=[checkpoint],\n",
    "                validation_data=vds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3183f646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:17:16.525550Z",
     "iopub.status.busy": "2022-02-23T01:17:16.524601Z",
     "iopub.status.idle": "2022-02-23T01:17:18.023049Z",
     "shell.execute_reply": "2022-02-23T01:17:18.023670Z",
     "shell.execute_reply.started": "2022-02-22T19:06:20.110174Z"
    },
    "papermill": {
     "duration": 15.418654,
     "end_time": "2022-02-23T01:17:18.023823",
     "exception": false,
     "start_time": "2022-02-23T01:17:02.605169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 01:17:17.489166: W tensorflow/core/util/tensor_slice_reader.cc:95] Could not open ./Checkpoint/cp.ckpt: Failed precondition: Checkpoint/cp.ckpt; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f505e7707d0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model = Autoencoder()\n",
    "new_model.load_weights(\"./Checkpoint/cp.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a7f0be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:17:45.962774Z",
     "iopub.status.busy": "2022-02-23T01:17:45.961165Z",
     "iopub.status.idle": "2022-02-23T01:17:45.963368Z",
     "shell.execute_reply": "2022-02-23T01:17:45.963774Z",
     "shell.execute_reply.started": "2022-02-22T19:06:22.601798Z"
    },
    "papermill": {
     "duration": 13.799914,
     "end_time": "2022-02-23T01:17:45.963908",
     "exception": false,
     "start_time": "2022-02-23T01:17:32.163994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "l = history.history.keys()\n",
    "metrics = list(l)\n",
    "df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64979836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:18:14.092082Z",
     "iopub.status.busy": "2022-02-23T01:18:14.091420Z",
     "iopub.status.idle": "2022-02-23T01:18:14.376668Z",
     "shell.execute_reply": "2022-02-23T01:18:14.376172Z",
     "shell.execute_reply.started": "2022-02-22T19:06:22.610587Z"
    },
    "papermill": {
     "duration": 14.001263,
     "end_time": "2022-02-23T01:18:14.376788",
     "exception": false,
     "start_time": "2022-02-23T01:18:00.375525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(len(l)//2):\n",
    "    tr = metrics[i]\n",
    "    val = \"val_\" + tr\n",
    "    df_pl= df[[tr,val]]\n",
    "    df_pl.rename(columns={tr:'Train',val:'Validation'},inplace=True)\n",
    "    df_pl.plot(title='Model '+tr,figsize=(12,8)).set(xlabel='Epoch',ylabel=tr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ed54b7",
   "metadata": {
    "papermill": {
     "duration": 14.048581,
     "end_time": "2022-02-23T01:18:42.713851",
     "exception": false,
     "start_time": "2022-02-23T01:18:28.665270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's try the model on a single example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e0c03521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:19:10.749482Z",
     "iopub.status.busy": "2022-02-23T01:19:10.748611Z",
     "iopub.status.idle": "2022-02-23T01:19:12.585141Z",
     "shell.execute_reply": "2022-02-23T01:19:12.585704Z",
     "shell.execute_reply.started": "2022-02-22T19:08:46.254440Z"
    },
    "papermill": {
     "duration": 15.589176,
     "end_time": "2022-02-23T01:19:12.585867",
     "exception": false,
     "start_time": "2022-02-23T01:18:56.996691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f505ed399d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = cv2.imread(\"/tmp/normal/Normal-1.png\", 1)\n",
    "img = cv2.resize(img, (224,224), interpolation=cv2.INTER_CUBIC)\n",
    "img_list = []\n",
    "img_list.append(np.array(img))\n",
    "x = np.asarray(img_list)\n",
    "recon = new_model.predict(x)\n",
    "plt.imshow(recon[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "650f4918",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T01:19:41.134404Z",
     "iopub.status.busy": "2022-02-23T01:19:41.132994Z",
     "iopub.status.idle": "2022-02-23T01:19:41.137703Z",
     "shell.execute_reply": "2022-02-23T01:19:41.138104Z",
     "shell.execute_reply.started": "2022-02-22T19:06:48.328194Z"
    },
    "papermill": {
     "duration": 14.313602,
     "end_time": "2022-02-23T01:19:41.138238",
     "exception": false,
     "start_time": "2022-02-23T01:19:26.824636",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.19795"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff = recon - x\n",
    "np.average(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c07c9d",
   "metadata": {
    "papermill": {
     "duration": 14.253113,
     "end_time": "2022-02-23T01:20:09.192810",
     "exception": false,
     "start_time": "2022-02-23T01:19:54.939697",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22258.695626,
   "end_time": "2022-02-23T01:20:27.036225",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-22T19:09:28.340599",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
